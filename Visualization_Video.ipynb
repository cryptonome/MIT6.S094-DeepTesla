{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对第十个视频预测方向盘转角，并生成可视化展示视频。  \n",
    "第十个视频文件名`epoch10_front.mkv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "* load model\n",
    "* slice video to images\n",
    "* get steering predicitons\n",
    "* visualizaiton （call `utils.visualize`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T16:34:45.773048Z",
     "start_time": "2018-03-04T16:34:26.703959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python \n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import subprocess as sp\n",
    "import itertools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from utils import visualize\n",
    "import params \n",
    "import imageio\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T16:37:30.890490Z",
     "start_time": "2018-03-04T16:37:25.711200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists, do you want to reuse? (y/n): y\n",
      "Model fetched from the disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 98, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 31, 98, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 47, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 47, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 22, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 20, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 18, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 253,803\n",
      "Trainable params: 253,011\n",
      "Non-trainable params: 792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Load model\n",
    "model = utils.get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T16:36:57.247603Z",
     "start_time": "2018-03-04T16:36:57.129773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  image Preprocess\n",
    "def img_pre_process(img, YUV=True):\n",
    "    \"\"\"\n",
    "    Processes the image and returns it\n",
    "    :param img: The image to be processed\n",
    "    :YUV=Ture, turn RGB to YUV, else keep RGB\n",
    "    :return: Returns the processed image(crop, resize, YUV, normalization)\n",
    "    \"\"\"\n",
    "    # Chop off 1/3 from the top and cut bottom 150px(which contains the head of car) img[240:570,:,:]\n",
    "    shape = img.shape\n",
    "    img_crop = img[int(shape[0]/3):shape[0]-150, 0:shape[1]]\n",
    "    \n",
    "    # Resize the image\n",
    "    img_resize = cv2.resize(img_crop, (200, 66), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    if YUV:\n",
    "        # RGB to YUV\n",
    "        img_yuv = cv2.cvtColor(img_resize, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "        # Normalize, need int???\n",
    "        img_nor = img_yuv/255.0\n",
    "    else:\n",
    "        img_nor = img_resize/255.0\n",
    "    assert img_nor.shape == (66,200,3)\n",
    "    assert img_nor.min() >= 0\n",
    "    assert img_nor.max() <= 1\n",
    "    \n",
    "    return img_nor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T16:38:10.387349Z",
     "start_time": "2018-03-04T16:37:36.523371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- processing video for epoch 10 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 80.35 Hz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Process video\n",
    "epoch_id = 10\n",
    "print('---------- processing video for epoch {} ----------'.format(epoch_id))\n",
    "\n",
    "   \n",
    "# convert mkv to mp4\n",
    "vid_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mkv'.format(epoch_id))\n",
    "vid_mp4_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mp4'.format(epoch_id))\n",
    "if not os.path.exists(vid_mp4_path):\n",
    "    mkv_to_mp4(vid_mkv_path, remove_mkv=False)    \n",
    "\n",
    "# slice mp4 to images\n",
    "vid = imageio.get_reader(vid_mp4_path,'ffmpeg')\n",
    "machine_steering = []\n",
    "frame_count = len(vid)\n",
    "\n",
    "## Steering Predictions\n",
    "print('performing inference...')\n",
    "time_start = time.time()\n",
    "for num in range(len(vid)):  \n",
    "    img = vid.get_data(num)\n",
    "    if img is not None:\n",
    "        img = img_pre_process(img)\n",
    "        assert img.shape==(66,200,3)\n",
    "        ste = float(model.predict(img.reshape(-1,*img.shape), batch_size=1))\n",
    "        machine_steering.append(ste)\n",
    "\n",
    "\n",
    "fps = frame_count / (time.time() - time_start)\n",
    "\n",
    "print('completed inference, total frames: {}, average fps: {} Hz'.format(frame_count, round(fps, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理2700张图像，用时15.76s，平均一张图像用时5.84ms;   \n",
    "预测2700图像22.04s，平均一张图像用时8.16ms;  \n",
    "预处理+预测 共用时37.8s，平均一张图像用时14ms, 也就是说每秒能处理71.4张图像  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T16:47:16.025139Z",
     "start_time": "2018-03-04T16:39:28.357216Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing visualization...\n",
      "completed 100 of 2700 frames\n",
      "completed 200 of 2700 frames\n",
      "completed 300 of 2700 frames\n",
      "completed 400 of 2700 frames\n",
      "completed 500 of 2700 frames\n",
      "completed 600 of 2700 frames\n",
      "completed 700 of 2700 frames\n",
      "completed 800 of 2700 frames\n",
      "completed 900 of 2700 frames\n",
      "completed 1000 of 2700 frames\n",
      "completed 1100 of 2700 frames\n",
      "completed 1200 of 2700 frames\n",
      "completed 1300 of 2700 frames\n",
      "completed 1400 of 2700 frames\n",
      "completed 1500 of 2700 frames\n",
      "completed 1600 of 2700 frames\n",
      "completed 1700 of 2700 frames\n",
      "completed 1800 of 2700 frames\n",
      "completed 1900 of 2700 frames\n",
      "completed 2000 of 2700 frames\n",
      "completed 2100 of 2700 frames\n",
      "completed 2200 of 2700 frames\n",
      "completed 2300 of 2700 frames\n",
      "completed 2400 of 2700 frames\n",
      "completed 2500 of 2700 frames\n",
      "completed 2600 of 2700 frames\n"
     ]
    }
   ],
   "source": [
    "## visualization\n",
    "print('performing visualization...')\n",
    "utils.visualize(epoch_id, machine_steering, params.out_dir,\n",
    "                    verbose=True, frame_count_limit=None)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
