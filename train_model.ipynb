{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T07:25:58.620530Z",
     "start_time": "2018-01-04T07:25:41.451585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Activation\n",
    "from keras.layers import Conv2D,MaxPooling2D,Lambda,Dropout,Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import h5py\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T03:54:14.882666Z",
     "start_time": "2017-12-26T03:53:56.593170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 ms, sys: 9.45 s, total: 9.49 s\n",
      "Wall time: 16.1 s\n",
      "CPU times: user 2.07 ms, sys: 6.03 ms, total: 8.1 ms\n",
      "Wall time: 24.9 ms\n",
      "CPU times: user 5.52 ms, sys: 1.05 s, total: 1.05 s\n",
      "Wall time: 2 s\n",
      "CPU times: user 1.1 ms, sys: 533 µs, total: 1.63 ms\n",
      "Wall time: 2.62 ms\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "import h5py\n",
    "\n",
    "h5f = h5py.File('./data/train.h5','r')\n",
    "%time X_train = h5f['image'][:]\n",
    "%time y_train = h5f['steering'][:]\n",
    "h5f.close()\n",
    "\n",
    "h5f2 = h5py.File('./data/test.h5','r')\n",
    "%time X_test = h5f2['image'][:]\n",
    "%time y_test = h5f2['steering'][:]\n",
    "h5f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T11:56:17.524165Z",
     "start_time": "2017-12-30T11:56:17.469299Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(5,5),strides=(2,2),activation='relu',padding='valid')(image_input)\n",
    "    x = Conv2D(36,(5,5),strides=(2,2),activation='relu',padding='valid')(x)\n",
    "#     x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(48,(5,5),strides=(2,2),activation='relu',padding='valid')(x)\n",
    "    \n",
    "    \n",
    "#     # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "#     x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T16:35:21.048964Z",
     "start_time": "2017-12-23T16:35:21.011650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24300, 66, 200, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T11:56:32.158396Z",
     "start_time": "2017-12-30T11:56:31.846014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reset graph\n",
    "K.clear_session()\n",
    "\n",
    "# model = build_model(inputs_shape=X_train.shape)\n",
    "model = build_model(inputs_shape=(24300, 66, 200, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T12:46:34.837835Z",
     "start_time": "2017-12-23T12:33:11.338650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21870 samples, validate on 2430 samples\n",
      "Epoch 1/20\n",
      "21870/21870 [==============================] - 287s - loss: 11.6652 - val_loss: 3.2986\n",
      "Epoch 2/20\n",
      "21870/21870 [==============================] - 254s - loss: 1.5485 - val_loss: 0.7466\n",
      "Epoch 3/20\n",
      "21870/21870 [==============================] - 250s - loss: 0.7658 - val_loss: 0.6074\n",
      "Epoch 4/20\n",
      "  704/21870 [..............................] - ETA: 271s - loss: 0.9753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-50ec3061aff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m              ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True)]    \n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#------------ train with early stop --------------\n",
    "from keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint\n",
    "\n",
    "\n",
    "filepath=\"./models/base_{val_loss:.3f}.h5\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',patience=5),\n",
    "             ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True)]    \n",
    "\n",
    "model.fit(X_train, y_train,epochs=20,batch_size=32,validation_split=0.1,callbacks=callbacks,shuffle=\"batch\")\n",
    "scores = model1.evaluate(X_test, y_test_label, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T12:52:46.174252Z",
     "start_time": "2017-12-23T12:52:32.510993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 11s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9817809388372631"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model_load = load_model('./models/base_0.747.h5')\n",
    "model_load.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "\n",
    "# reset graph\n",
    "K.clear_session()\n",
    "\n",
    "model = build_model(inputs_shape=X_train.shape)\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T07:40:48.839429Z",
     "start_time": "2017-12-23T16:38:24.517193Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------training model basic----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n",
      "20655/20655 [==============================] - 255s - loss: 12.8659 - val_loss: 4.2837\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 239s - loss: 2.1452 - val_loss: 1.1969\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 229s - loss: 0.8160 - val_loss: 0.6555\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 235s - loss: 0.5081 - val_loss: 0.4802\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 215s - loss: 0.4118 - val_loss: 0.4165\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 217s - loss: 0.3582 - val_loss: 0.2714\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 212s - loss: 0.3051 - val_loss: 0.2665\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 208s - loss: 0.2814 - val_loss: 0.4702\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 210s - loss: 0.2920 - val_loss: 0.2372\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 212s - loss: 0.2205 - val_loss: 0.2184\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 208s - loss: 0.2206 - val_loss: 0.2892\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 212s - loss: 0.2361 - val_loss: 0.1834\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 207s - loss: 0.2389 - val_loss: 0.1985\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 211s - loss: 0.2308 - val_loss: 0.3037\n",
      "Epoch 15/20\n",
      "20655/20655 [==============================] - 211s - loss: 0.2209 - val_loss: 0.1839\n",
      "Epoch 16/20\n",
      "20655/20655 [==============================] - 205s - loss: 0.1529 - val_loss: 0.1518\n",
      "Epoch 17/20\n",
      "20655/20655 [==============================] - 210s - loss: 0.1788 - val_loss: 0.3150\n",
      "Epoch 18/20\n",
      "20655/20655 [==============================] - 208s - loss: 0.1949 - val_loss: 0.1463\n",
      "Epoch 19/20\n",
      "20655/20655 [==============================] - 210s - loss: 0.1513 - val_loss: 0.1716\n",
      "Epoch 20/20\n",
      "20655/20655 [==============================] - 213s - loss: 0.1505 - val_loss: 0.1901\n",
      "------------------------trining model basic, score 3.119313227159006, using time 4338.039994001389 \n",
      "\n",
      "---------------------------training model BN----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n",
      "20655/20655 [==============================] - 330s - loss: 4.5761 - val_loss: 13.6687\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 320s - loss: 1.2164 - val_loss: 0.8586\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 318s - loss: 0.8620 - val_loss: 2.0240\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 318s - loss: 0.7253 - val_loss: 0.4052\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 313s - loss: 0.6356 - val_loss: 0.3148\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 314s - loss: 0.5907 - val_loss: 0.4606\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 313s - loss: 0.5631 - val_loss: 1.2377\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 316s - loss: 0.5359 - val_loss: 0.2155\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 322s - loss: 0.5110 - val_loss: 0.9718\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 320s - loss: 0.5088 - val_loss: 0.5547\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 313s - loss: 0.4970 - val_loss: 0.2348\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 320s - loss: 0.4719 - val_loss: 0.4955\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 315s - loss: 0.4776 - val_loss: 0.3606\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 317s - loss: 0.4762 - val_loss: 0.2183\n",
      "------------------------trining model BN, score 2.8302908685472277, using time 4460.9515290260315 \n",
      "\n",
      "---------------------------training model pool----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n",
      "20655/20655 [==============================] - 764s - loss: 10.6367 - val_loss: 2.6633\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 756s - loss: 1.5760 - val_loss: 0.9114\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 748s - loss: 0.8280 - val_loss: 0.7769\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 754s - loss: 0.5396 - val_loss: 0.4196\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 761s - loss: 0.3931 - val_loss: 0.3170\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 755s - loss: 0.3432 - val_loss: 0.3511\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 747s - loss: 0.3303 - val_loss: 0.2416\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 759s - loss: 0.2487 - val_loss: 0.2561\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 758s - loss: 0.2479 - val_loss: 0.2141\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 757s - loss: 0.2471 - val_loss: 0.2492\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 742s - loss: 0.2528 - val_loss: 0.2550\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 757s - loss: 0.2355 - val_loss: 0.3521\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 759s - loss: 0.1864 - val_loss: 0.2473\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 758s - loss: 0.2076 - val_loss: 0.1476\n",
      "Epoch 15/20\n",
      "20655/20655 [==============================] - 758s - loss: 0.1788 - val_loss: 0.1763\n",
      "Epoch 16/20\n",
      "20655/20655 [==============================] - 746s - loss: 0.2037 - val_loss: 0.1633\n",
      "Epoch 17/20\n",
      "20655/20655 [==============================] - 750s - loss: 0.1985 - val_loss: 0.1818\n",
      "Epoch 18/20\n",
      "20655/20655 [==============================] - 758s - loss: 0.1958 - val_loss: 0.1661\n",
      "Epoch 19/20\n",
      "20655/20655 [==============================] - 763s - loss: 0.2023 - val_loss: 0.1379\n",
      "Epoch 20/20\n",
      "20655/20655 [==============================] - 761s - loss: 0.1348 - val_loss: 0.1428\n",
      "------------------------trining model pool, score 3.2402693656638815, using time 15128.657741069794 \n",
      "\n",
      "---------------------------training model drop----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n",
      "20655/20655 [==============================] - 209s - loss: 19.7816 - val_loss: 10.8169\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 204s - loss: 6.6666 - val_loss: 2.4400\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 213s - loss: 2.5727 - val_loss: 1.1647\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 216s - loss: 1.8403 - val_loss: 0.9144\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 209s - loss: 1.4610 - val_loss: 0.6496\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 211s - loss: 1.1854 - val_loss: 0.5449\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 216s - loss: 1.0702 - val_loss: 1.1752\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 207s - loss: 1.0194 - val_loss: 0.5794\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 210s - loss: 0.8922 - val_loss: 0.4329\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 213s - loss: 0.7817 - val_loss: 0.9789\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 213s - loss: 0.7832 - val_loss: 0.5254\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 215s - loss: 0.6781 - val_loss: 0.4556\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 208s - loss: 0.6498 - val_loss: 0.5980\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 207s - loss: 0.6220 - val_loss: 0.5651\n",
      "Epoch 15/20\n",
      "20655/20655 [==============================] - 207s - loss: 0.5895 - val_loss: 0.4164\n",
      "Epoch 16/20\n",
      "20655/20655 [==============================] - 212s - loss: 0.6194 - val_loss: 0.4463\n",
      "Epoch 17/20\n",
      "20655/20655 [==============================] - 209s - loss: 0.5697 - val_loss: 0.5424\n",
      "Epoch 18/20\n",
      "20655/20655 [==============================] - 206s - loss: 0.5116 - val_loss: 0.4625\n",
      "Epoch 19/20\n",
      "20655/20655 [==============================] - 211s - loss: 0.4825 - val_loss: 0.4452\n",
      "Epoch 20/20\n",
      "20655/20655 [==============================] - 212s - loss: 0.4909 - val_loss: 0.6185\n",
      "------------------------trining model drop, score 2.327647100554572, using time 4218.319137096405 \n",
      "\n",
      "---------------------------training model smallkernel----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20655/20655 [==============================] - 973s - loss: 11.8340 - val_loss: 2.8978\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 955s - loss: 1.9303 - val_loss: 0.9288\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 966s - loss: 0.8392 - val_loss: 0.7590\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 990s - loss: 0.5028 - val_loss: 0.4158\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 971s - loss: 0.4219 - val_loss: 0.2955\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 980s - loss: 0.3576 - val_loss: 0.3133\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 1093s - loss: 0.2686 - val_loss: 0.2703\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 1044s - loss: 0.2829 - val_loss: 0.3045\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 1038s - loss: 0.2320 - val_loss: 0.2269\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 994s - loss: 0.2644 - val_loss: 0.2435\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 1010s - loss: 0.2466 - val_loss: 0.2670\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 988s - loss: 0.2559 - val_loss: 0.1945\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 1088s - loss: 0.1826 - val_loss: 0.1845\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 1048s - loss: 0.2040 - val_loss: 0.1647\n",
      "Epoch 15/20\n",
      "20655/20655 [==============================] - 1049s - loss: 0.1900 - val_loss: 0.1918\n",
      "Epoch 16/20\n",
      "20655/20655 [==============================] - 993s - loss: 0.4185 - val_loss: 0.2508\n",
      "Epoch 17/20\n",
      "20655/20655 [==============================] - 1018s - loss: 0.1563 - val_loss: 0.1288\n",
      "Epoch 18/20\n",
      "20655/20655 [==============================] - 1014s - loss: 0.1504 - val_loss: 0.1390\n",
      "Epoch 19/20\n",
      "20655/20655 [==============================] - 1178s - loss: 0.1513 - val_loss: 0.1779\n",
      "Epoch 20/20\n",
      "20655/20655 [==============================] - 1308s - loss: 0.1614 - val_loss: 0.1253\n",
      "------------------------trining model smallkernel, score 3.3091933691943134, using time 20713.746075868607 \n",
      "\n",
      "---------------------------training model RGB----------------------\n",
      "\n",
      "Train on 20655 samples, validate on 3645 samples\n",
      "Epoch 1/20\n",
      "20655/20655 [==============================] - 242s - loss: 9.0858 - val_loss: 2.9128\n",
      "Epoch 2/20\n",
      "20655/20655 [==============================] - 249s - loss: 1.7691 - val_loss: 1.1002\n",
      "Epoch 3/20\n",
      "20655/20655 [==============================] - 234s - loss: 0.7993 - val_loss: 0.6173\n",
      "Epoch 4/20\n",
      "20655/20655 [==============================] - 258s - loss: 0.5210 - val_loss: 0.5092\n",
      "Epoch 5/20\n",
      "20655/20655 [==============================] - 252s - loss: 0.4379 - val_loss: 0.5656\n",
      "Epoch 6/20\n",
      "20655/20655 [==============================] - 262s - loss: 0.3635 - val_loss: 0.3236\n",
      "Epoch 7/20\n",
      "20655/20655 [==============================] - 241s - loss: 0.3065 - val_loss: 0.2894\n",
      "Epoch 8/20\n",
      "20655/20655 [==============================] - 246s - loss: 0.2925 - val_loss: 0.2612\n",
      "Epoch 9/20\n",
      "20655/20655 [==============================] - 258s - loss: 0.2854 - val_loss: 0.2740\n",
      "Epoch 10/20\n",
      "20655/20655 [==============================] - 264s - loss: 0.2188 - val_loss: 0.2915\n",
      "Epoch 11/20\n",
      "20655/20655 [==============================] - 278s - loss: 0.2948 - val_loss: 0.3755\n",
      "Epoch 12/20\n",
      "20655/20655 [==============================] - 238s - loss: 0.2634 - val_loss: 0.2891\n",
      "Epoch 13/20\n",
      "20655/20655 [==============================] - 255s - loss: 0.2037 - val_loss: 0.2038\n",
      "Epoch 14/20\n",
      "20655/20655 [==============================] - 225s - loss: 0.1831 - val_loss: 0.2039\n",
      "Epoch 15/20\n",
      "20655/20655 [==============================] - 272s - loss: 0.1715 - val_loss: 0.2257\n",
      "Epoch 16/20\n",
      "20655/20655 [==============================] - 280s - loss: 0.2056 - val_loss: 0.2020\n",
      "Epoch 17/20\n",
      "20655/20655 [==============================] - 260s - loss: 0.1550 - val_loss: 0.3968\n",
      "Epoch 18/20\n",
      "20655/20655 [==============================] - 252s - loss: 0.1804 - val_loss: 0.1588\n",
      "Epoch 19/20\n",
      "20655/20655 [==============================] - 227s - loss: 0.1554 - val_loss: 0.1503\n",
      "Epoch 20/20\n",
      "20655/20655 [==============================] - 270s - loss: 0.1561 - val_loss: 0.1711\n",
      "------------------------trining model RGB, score 9.345003208584256, using time 5077.383208990097 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs_shape = X_train.shape\n",
    "\n",
    "model_names = ['basic','BN', 'pool','drop','smallkernel','RGB']\n",
    "models = [build_model(inputs_shape=inputs_shape),\n",
    "         build_model_BN(inputs_shape=inputs_shape),\n",
    "         build_model_pool(inputs_shape=inputs_shape),\n",
    "         build_model_drop(inputs_shape=inputs_shape),\n",
    "         build_model_small(inputs_shape=inputs_shape),\n",
    "         build_model(inputs_shape=inputs_shape)]\n",
    "\n",
    "train_histories=[]\n",
    "for model_name, model in zip(model_names, models):\n",
    "    filepath=\"./models/\"+model_name + \"{epoch:2d}_{val_loss:.3f}.h5\"\n",
    "    callbacks = [EarlyStopping(monitor='val_loss',patience=5),\n",
    "                 ModelCheckpoint(filepath, monitor='val_loss',save_best_only=False)]    \n",
    "    print(\"---------------------------training model {}----------------------\\n\".format(model_name))\n",
    "    if model_name!='RGB':\n",
    "#         if (not X_train.any()) or (not y_train):\n",
    "#             del X_trainRGB\n",
    "#             del y_trainRGB\n",
    "        \n",
    "#             h5f = h5py.File('data/train.h5','r')\n",
    "#             X_train = h5f['image'][:]\n",
    "#             y_train = h5f['steering'][:]\n",
    "#             h5f.close()\n",
    "\n",
    "        start_time = time.time()\n",
    "        his = model.fit(X_train, y_train,epochs=20,batch_size=64,validation_split=0.15,callbacks=callbacks,shuffle=\"batch\")\n",
    "        end_time = time.time()\n",
    "        score = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(\"------------------------trining model {}, score {}, using time {} \\n\".format(model_name,score,end_time-start_time))\n",
    "        train_histories.append(his)\n",
    "    else:\n",
    "#         if (not X_trainRGB) or (not y_trainRGB):\n",
    "        del X_train\n",
    "        del y_train\n",
    "\n",
    "        h5f = h5py.File('data/RGBtrain.h5','r')\n",
    "        X_trainRGB = h5f['image'][:]\n",
    "        y_trainRGB = h5f['steering'][:]\n",
    "        h5f.close()\n",
    "\n",
    "        h5f = h5py.File('data/RGBtest.h5','r')\n",
    "        X_testRGB = h5f['image'][:]\n",
    "        y_testRGB = h5f['steering'][:]\n",
    "        h5f.close()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        his = model.fit(X_trainRGB, y_trainRGB,epochs=20,batch_size=64,validation_split=0.15,callbacks=callbacks,shuffle=\"batch\")\n",
    "        end_time = time.time()\n",
    "        score = model.evaluate(X_testRGB, y_testRGB, verbose=0)\n",
    "        print(\"------------------------trining model {}, score {}, using time {} \\n\".format(model_name,score,end_time-start_time))\n",
    "        train_histories.append(his)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:03:27.110491Z",
     "start_time": "2017-12-24T14:03:26.901935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:03:36.496980Z",
     "start_time": "2017-12-24T14:03:34.338129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Visualize training history\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
    "# list all data in history\n",
    "print(train_histories[0].history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:09:55.531959Z",
     "start_time": "2017-12-24T14:09:55.519131Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [12.865852948892668,\n",
       "  2.1452265116903515,\n",
       "  0.81599241910965381,\n",
       "  0.50808101209420264,\n",
       "  0.41181428323528491,\n",
       "  0.35816607826473462,\n",
       "  0.30513564062678361,\n",
       "  0.28135196751700969,\n",
       "  0.29199657938405926,\n",
       "  0.22048272773086,\n",
       "  0.2206278509636013,\n",
       "  0.23613613018095567,\n",
       "  0.23893074859966235,\n",
       "  0.23075886265154008,\n",
       "  0.22087175293699993,\n",
       "  0.1529453416246965,\n",
       "  0.17875619289575492,\n",
       "  0.19493860894269904,\n",
       "  0.15132823939027351,\n",
       "  0.15052797779408417],\n",
       " 'val_loss': [4.2836828612496332,\n",
       "  1.1969487054848376,\n",
       "  0.6554765456007341,\n",
       "  0.48017196768922898,\n",
       "  0.41652746171127131,\n",
       "  0.27144998776405765,\n",
       "  0.26651854777532352,\n",
       "  0.47015520037446984,\n",
       "  0.23719617249380251,\n",
       "  0.21843116202472168,\n",
       "  0.28918603862264031,\n",
       "  0.18344750026207729,\n",
       "  0.19846771963666332,\n",
       "  0.30370058066151595,\n",
       "  0.18394786227795976,\n",
       "  0.15182830252683374,\n",
       "  0.31497174452361748,\n",
       "  0.1463180857757809,\n",
       "  0.17157865615129797,\n",
       "  0.19010438291951298]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_histories[0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:04:56.691716Z",
     "start_time": "2017-12-24T14:04:56.303346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyhwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x33bb92978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(train_histories[0].history['loss'])\n",
    "plt.plot(train_histories[0].history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T07:26:32.350717Z",
     "start_time": "2018-01-04T07:26:31.876578Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_BN(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(5,5),strides=(2,2),padding='valid')(image_input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Conv2D(36,(5,5),strides=(2,2),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "#     x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(48,(5,5),strides=(2,2),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    \n",
    "#     # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "#     x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Dense(50)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Dense(10)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T07:26:45.026011Z",
     "start_time": "2018-01-04T07:26:44.119491Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 98, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 31, 98, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 47, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 47, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 22, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 20, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 18, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 253,803\n",
      "Trainable params: 253,011\n",
      "Non-trainable params: 792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# model = build_model(inputs_shape=X_train.shape)\n",
    "model = build_model_BN(inputs_shape=(24300, 66, 200, 3))\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using stride=1 and max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T12:01:11.387766Z",
     "start_time": "2017-12-30T12:01:11.318538Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_pool(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(5,5),strides=(1,1),activation='relu',padding='same')(image_input)\n",
    "    x = MaxPooling2D((2,2))(x)    \n",
    "    x = Conv2D(36,(5,5),strides=(1,1),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(48,(5,5),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    \n",
    "#     # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T16:25:39.429426Z",
     "start_time": "2017-12-23T16:25:39.055551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 66, 200, 24)       1824      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 33, 100, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 33, 100, 36)       21636     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 50, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 46, 48)        43248     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 23, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 21, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 19, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               243300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 380,219\n",
      "Trainable params: 380,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = build_model_pool(inputs_shape=X_train.shape)\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T15:18:32.841578Z",
     "start_time": "2017-12-23T15:18:32.764294Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_drop(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(5,5),strides=(2,2),activation='relu',padding='valid')(image_input)\n",
    "    x = Conv2D(36,(5,5),strides=(2,2),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(48,(5,5),strides=(2,2),activation='relu',padding='valid')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "#     # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T15:18:40.403986Z",
     "start_time": "2017-12-23T15:18:39.978277Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = build_model_drop(inputs_shape=X_train.shape)\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\\*(3\\*3)conv -> (5\\*5) conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T15:22:10.025630Z",
     "start_time": "2017-12-23T15:22:09.910771Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model_small(inputs_shape=None, activation='relu', optimizer = 'adam', loss='mse'):\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(3,3),strides=(1,1),activation='relu',padding='valid')(image_input)\n",
    "    x = Conv2D(24,(3,3),strides=(1,1),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)    \n",
    "    x = Conv2D(36,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(36,(3,3),strides=(1,1),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(48,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(48,(3,3),strides=(1,1),activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    \n",
    "    # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T15:22:10.937149Z",
     "start_time": "2017-12-23T15:22:10.530518Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 198, 24)       672       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 198, 24)       5208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 99, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 97, 36)        7812      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 97, 36)        11700     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 48, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 46, 48)        15600     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 46, 48)        20784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 23, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 21, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 19, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               243300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 375,287\n",
      "Trainable params: 375,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = build_model_small(inputs_shape=X_train.shape)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv -> fc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine basic model+ dropout+BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到计算资源有限，对模型先进行超参数网格搜索调优，缩小范围后再进行随机搜索调优。    \n",
    "调优参数: \n",
    "* dropout rate：(0.1, 0.2, 0.3)\n",
    "* learning rate：(0.001，0.01，0.05)，\n",
    "Train epoch number: 30; Early stop: 5 epoch.   \n",
    "(0.3, 0.001)和(0.3, 0.01)两组参数的模型效果在所有结果中是最好。测试集上的均方差值分别为2.05和2.08。   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T13:37:47.573054Z",
     "start_time": "2017-12-30T13:37:28.004610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,CSVLogger,ModelCheckpoint\n",
    "import itertools\n",
    "from keras.layers import Input,Dense,Activation,Flatten\n",
    "from keras.layers import Conv2D,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "\n",
    "# ---------------------------build model--------------------\n",
    "def build_model(inputs_shape=None, activation='relu', dropout=0.2, learning_rate=0.001, loss='mse'):\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    image_input = Input(shape=inputs_shape[1:])\n",
    "    # use strided convolutions in the ﬁrst three convolutional layers with a 2×2 stride and a 5×5 kernel and \n",
    "    x = Conv2D(24,(5,5),strides=(2,2),padding='valid')(image_input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Conv2D(36,(5,5),strides=(2,2),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Conv2D(48,(5,5),strides=(2,2),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    \n",
    "#     # a non-strided convolution with a 3×3 kernel size in the last two convolutional layers\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "\n",
    "    x = Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='valid')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Dense(50)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    x = Dense(10)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    out = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=out)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss =loss)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T13:38:35.481174Z",
     "start_time": "2017-12-30T13:38:34.466100Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 98, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 31, 98, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 47, 36)        144       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 47, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 22, 48)         192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 22, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 20, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 18, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 253,803\n",
      "Trainable params: 253,011\n",
      "Non-trainable params: 792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  model = build_model(inputs_shape=X_train.shape, dropout=p[0], learning_rate=p[1])\n",
    "    \n",
    "K.clear_session()\n",
    "\n",
    "# model = build_model(inputs_shape=X_train.shape)\n",
    "model = build_model(inputs_shape=(24300, 66, 200, 3))\n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T04:05:22.029631Z",
     "start_time": "2017-12-26T04:05:22.015866Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizers = ['adam','rmsprop']\n",
    "# activations = ['PReLU','relu','LeakyReLU']\n",
    "# activations_ps = ['relu']\n",
    "dropouts = [0.1,0.2,0.3]\n",
    "learning_rates = [0.001, 0.01, 0.05]\n",
    "parameters = itertools.product(dropouts,learning_rates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filepath=\"./models/basicBNdrop_{epoch:03d}:{val_loss:.3f}.h5\"\n",
    "# callbacks = [EarlyStopping(monitor='val_loss',patience=5)\n",
    "#              ,ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True)]     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T14:15:35.268846Z",
     "start_time": "2017-12-25T13:31:23.593176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "using parameters: (0.1, 0.05)\n",
      "\n",
      "Train on 44270 samples, validate on 2330 samples\n",
      "Epoch 1/1\n",
      "44270/44270 [==============================] - 801s - loss: 10.7804 - val_loss: 25.9898\n",
      "2700/2700 [==============================] - 21s    \n",
      "test score: 8.01518350319 with (0.1, 0.05) \n",
      " \n",
      " \n",
      "****************************************************************************************************\n",
      "using parameters: (0.2, 0.001)\n",
      "\n",
      "Train on 44270 samples, validate on 2330 samples\n",
      "Epoch 1/1\n",
      "44270/44270 [==============================] - 766s - loss: 9.4114 - val_loss: 9.2264\n",
      "2700/2700 [==============================] - 21s    \n",
      "test score: 2.93338235502 with (0.2, 0.001) \n",
      " \n",
      " \n",
      "****************************************************************************************************\n",
      "using parameters: (0.2, 0.01)\n",
      "\n",
      "Train on 44270 samples, validate on 2330 samples\n",
      "Epoch 1/1\n",
      "44270/44270 [==============================] - 799s - loss: 9.6839 - val_loss: 23.7399\n",
      "2700/2700 [==============================] - 22s    \n",
      "test score: 8.58764126071 with (0.2, 0.01) \n",
      " \n",
      " \n",
      "****************************************************************************************************\n",
      "using parameters: (0.2, 0.05)\n",
      "\n",
      "Train on 44270 samples, validate on 2330 samples\n",
      "Epoch 1/1\n",
      "11328/44270 [======>.......................] - ETA: 539s - loss: 19.0437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-346dc917b4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'using parameters: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test score:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'with {} \\n \\n '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in parameters:\n",
    "    K.clear_session()\n",
    "    model = build_model(inputs_shape=X_train.shape, dropout=p[0], learning_rate=p[1])\n",
    "    print('*'*100)\n",
    "    print('using parameters: '+str(p)+'\\n')\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=64, validation_split=0.05, callbacks=callbacks, shuffle=\"batch\")\n",
    "    score = model.evaluate(X_test,y_test)\n",
    "    print('test score:',score,'with {} \\n \\n '.format(p))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T04:18:36.546041Z",
     "start_time": "2017-12-26T04:18:36.475462Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, X, y, p, max_wait_epochs=5,n_epochs=20, model_path='./models/basicBNdrop_{}_{}'.format(p[0],p[1])):\n",
    "    best_score = 1000.\n",
    "    best_epoch = 1\n",
    "    best_model = None\n",
    "    scores_his = []\n",
    "    cnt = 0\n",
    "    \n",
    "    print(\"\\n**********************************************************************\")\n",
    "    print(\"using parameter: dropout={}, learningrate={} \\n\".format(p[0],p[1]))\n",
    "    for i in range(n_epochs):\n",
    "        model.fit(X, y, epochs=1, batch_size=64, validation_split=0.05, shuffle=\"batch\")\n",
    "        cur_score=model.evaluate(X_test,y_test)\n",
    "        scores_his.append(cur_score)\n",
    "        print(\"Epoch {}, current test score: {:.4f}\".format(i+1, cur_score))\n",
    "        \n",
    "        if cur_score < best_score:\n",
    "            best_score = cur_score\n",
    "            best_model = model\n",
    "            best_epoch = i+1\n",
    "            model.save(model_path+'_epoch{}_{:.3f}.h5'.format(i+1,cur_score))\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt+=1\n",
    "        if (cnt >= max_wait_epochs) or (cur_score>1000):\n",
    "            break\n",
    "    print(\"**********************************************************************\")\n",
    "    print(\"using parameter: dropout={}, learningrate={}\".format(p[0],p[1]))\n",
    "    print(\"train {} epochs, best score: {} in epoch: {} \\n\".format(i+1, best_score, best_epoch))\n",
    "\n",
    "    return best_model, best_score, scores_his\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T04:24:13.429999Z",
     "start_time": "2017-12-26T04:18:40.086641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.001 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 3s - loss: 23.2152 - val_loss: 39.1025\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 1, current test score: 7.9001\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 2s - loss: 20.1974 - val_loss: 39.2083\n",
      "2700/2700 [==============================] - 15s    \n",
      "Epoch 2, current test score: 7.9933\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 16.5743 - val_loss: 39.1756\n",
      "2700/2700 [==============================] - 14s    \n",
      "Epoch 3, current test score: 7.9785\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 16.4598 - val_loss: 39.2086\n",
      "2700/2700 [==============================] - 14s    \n",
      "Epoch 4, current test score: 8.0137\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.001\n",
      "train 4 epochs, best score: 7.900071037433766 in epoch: 1 \n",
      "\n",
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.01 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 3s - loss: 21.3415 - val_loss: 43.5656\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 1, current test score: 16.5426\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 21.0366 - val_loss: 587.4277\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 2, current test score: 625.3239\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 18.6010 - val_loss: 13618.6406\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 3, current test score: 13443.9736\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.01\n",
      "train 3 epochs, best score: 16.54262533823649 in epoch: 1 \n",
      "\n",
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.05 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 3s - loss: 20.2278 - val_loss: 748602.8750\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 1, current test score: 1249077.2154\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.2, learningrate=0.05\n",
      "train 1 epochs, best score: 1000.0 in epoch: 1 \n",
      "\n",
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.001 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 3s - loss: 26.6733 - val_loss: 38.9978\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 1, current test score: 7.7805\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 20.6707 - val_loss: 39.0989\n",
      "2700/2700 [==============================] - 15s    \n",
      "Epoch 2, current test score: 7.8977\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 19.0432 - val_loss: 39.1466\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 3, current test score: 7.9871\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 18.7668 - val_loss: 39.1974\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 4, current test score: 8.0683\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.001\n",
      "train 4 epochs, best score: 7.780523223170528 in epoch: 1 \n",
      "\n",
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.01 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 3s - loss: 23.2006 - val_loss: 40.9147\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 1, current test score: 11.3174\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 19.7017 - val_loss: 154.2626\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 2, current test score: 174.0427\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 18.5459 - val_loss: 4894.2329\n",
      "2700/2700 [==============================] - 16s    \n",
      "Epoch 3, current test score: 6604.7453\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.01\n",
      "train 3 epochs, best score: 11.317412174366138 in epoch: 1 \n",
      "\n",
      "\n",
      " **********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.05 \n",
      "\n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 5s - loss: 22.3950 - val_loss: 22681906.0000\n",
      "2700/2700 [==============================] - 21s    \n",
      "Epoch 1, current test score: 26851596.3526\n",
      "**********************************************************************\n",
      "using parameter: dropout=0.3, learningrate=0.05\n",
      "train 1 epochs, best score: 1000.0 in epoch: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = 10\n",
    "\n",
    "for p in parameters:\n",
    "    K.clear_session()\n",
    "    model = build_model(inputs_shape=X_train.shape, dropout=p[0], learning_rate=p[1])\n",
    "    \n",
    "    cur_best_model, cur_best_score, cur_scores_his = train_model(model, X_train[:128], y_train[:128], p, \n",
    "                                     max_wait_epochs=3,n_epochs=10, \n",
    "                                     model_path='./models/basicBNdrop_{}_{}'.format(p[0],p[1]))\n",
    "    \n",
    "    if cur_best_score < best_score:\n",
    "        best_score = cur_best_score\n",
    "        best_model = cur_best_model\n",
    "        best_scores_his = cur_scores_his\n",
    "#     model.fit(X_train, y_train, epochs=1, batch_size=64, validation_split=0.05, callbacks=callbacks, shuffle=\"batch\")\n",
    "#     score = model.evaluate(X_test,y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('test score:',score,'with {} \\n \\n '.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T03:19:50.911062Z",
     "start_time": "2017-12-26T03:18:30.076264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 4s - loss: 20.2382 - val_loss: 13.4933\n",
      "2700/2700 [==============================] - 18s    \n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 19.0601 - val_loss: 13.4554\n",
      "2700/2700 [==============================] - 16s    \n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 19.8305 - val_loss: 13.4004\n",
      "2700/2700 [==============================] - 15s    \n",
      "Train on 121 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "121/121 [==============================] - 1s - loss: 16.5464 - val_loss: 13.3854\n",
      "2700/2700 [==============================] - 15s    \n",
      "----------------------------------------\n",
      "using parameter: dropout=0.1, learningrate=0.01\n",
      "train 10 epochs, best score: 7.959995614952511 in epoch: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model(inputs_shape=X_train.shape)\n",
    "p=[0.1, 0.01]\n",
    "best_model, best_score, scores_his = train_model(model, X_train[:128], y_train[:128], p, \n",
    "                                     max_wait_epochs=3,n_epochs=10, \n",
    "                                     model_path='./models/basicBNdrop_{}_{}'.format(p[0],p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "接下来利用随机搜索进行超参数调优，   \n",
    "在0.001-0.01范围内随机选择6个值作为learning rate，   \n",
    "在0.25-0.35范围内随机选择3个值作为dropout rate，两两组合后共得到18组超参数。   \n",
    "(0.329172504，0.001904038)这组参数得到了非常喜人的成绩，测试集上的均方差值只有1.79。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#----------------using random search\n",
    "np.random.seed(0)\n",
    "dropouts = list(0.1*np.random.rand(3)+0.25)\n",
    "\n",
    "r = -1*np.random.rand(6)-2\n",
    "learning_rates = list(10**r)\n",
    "learning_rates.append(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T12:06:53.389251Z",
     "start_time": "2017-12-26T12:06:51.523979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 935 ms, total: 940 ms\n",
      "Wall time: 1.83 s\n",
      "CPU times: user 1.92 ms, sys: 2.47 ms, total: 4.39 ms\n",
      "Wall time: 10.2 ms\n"
     ]
    }
   ],
   "source": [
    "h5f2 = h5py.File('./data/test.h5','r')\n",
    "%time X_test = h5f2['image'][:]\n",
    "%time y_test = h5f2['steering'][:]\n",
    "h5f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T12:10:50.459641Z",
     "start_time": "2017-12-26T12:10:19.827451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 20s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7855939465981943"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./models/basicBNdrop_0.32917250380826646_0.0019040375394559835_epoch2_1.786.h5')\n",
    "model.evaluate(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T12:15:10.774778Z",
     "start_time": "2017-12-26T12:15:10.743227Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model architecture into a json file\n",
    "json_string = model.to_json()\n",
    "\n",
    "with open('./models/model.json', 'w') as outfile:\n",
    "        outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-26T12:16:15.727520Z",
     "start_time": "2017-12-26T12:16:15.406064Z"
    }
   },
   "outputs": [],
   "source": [
    "# only save weights\n",
    "model.save_weights('./models/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "231px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
